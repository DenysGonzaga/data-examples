{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DenysNunes/data-examples/blob/main/spark/2%20-%20intermediate/basic_delta_lake_usage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkIFMrWkIlG9"
      },
      "source": [
        "## Delta Lake Example\n",
        "\n",
        "Example using Delta Lake third party library to enable lakehouse features. <br>\n",
        "Delta Lake provides ACID transactions, scalable metadata handling, and unifies streaming and batch data processing on top of existing data lakes, such as S3, ADLS, GCS, and HDFS. <br>\n",
        "Read more about [here](https://delta.io/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr6TvorKJogD"
      },
      "source": [
        "## ▶ Initializing spark\n",
        "\n",
        "Creating a session with default configurations and all dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc8NFVUFIW-9",
        "outputId": "55b3d792-c23a-4908-f760-a9cc8a9b5b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 281.3 MB 38 kB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 61.3 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q pyspark==3.2.0\n",
        "!rm -rf /tmp/tables/\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, expr\n",
        "from pyspark.sql.types import StructType\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName(\"New Session Example\") \\\n",
        "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
        "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:1.1.0\") \\\n",
        "    .enableHiveSupport() \\\n",
        "    .getOrCreate()\n",
        "\n",
        "from delta.tables import DeltaTable\n",
        "\n",
        "person_path = '/tmp/tables/tb_person/'\n",
        "table_meta = {\n",
        "   \"fields\":[\n",
        "      {\n",
        "         \"metadata\":{\n",
        "             \"comment\": \"Person id.\"\n",
        "         },\n",
        "         \"name\":\"id\",\n",
        "         \"nullable\": False,\n",
        "         \"type\":\"integer\"\n",
        "      },\n",
        "      {\n",
        "         \"metadata\":{\n",
        "             \"comment\": \"Person name information.\"\n",
        "         },\n",
        "         \"name\":\"name\",\n",
        "         \"nullable\": False,\n",
        "         \"type\":\"string\"\n",
        "      },\n",
        "      {\n",
        "         \"metadata\":{\n",
        "             \"comment\": \"Person salary information.\"\n",
        "         },\n",
        "         \"name\":\"salary\",\n",
        "         \"nullable\": False,\n",
        "         \"type\":\"float\"\n",
        "      },\n",
        "      {\n",
        "         \"metadata\":{\n",
        "             \"comment\": \"Person gender information.\"\n",
        "         },\n",
        "         \"name\":\"gender\",\n",
        "         \"nullable\": False,\n",
        "         \"type\":\"string\"\n",
        "      },\n",
        "      {\n",
        "         \"metadata\":{\n",
        "             \"comment\": \"Moment when data inserted.\"\n",
        "         },\n",
        "         \"name\":\"inserted_at\",\n",
        "         \"nullable\": False,\n",
        "         \"type\":\"timestamp\"\n",
        "      },\n",
        "      {\n",
        "         \"metadata\":{\n",
        "             \"comment\": \"Moment when data updated.\"\n",
        "         },\n",
        "         \"name\": \"updated_at\",\n",
        "         \"nullable\": True,\n",
        "         \"type\":\"timestamp\"\n",
        "      }\n",
        "   ],\n",
        "   \"type\":\"struct\"\n",
        "}\n",
        "\n",
        "table_schema = StructType.fromJson(table_meta)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxW9gKzHP-pI"
      },
      "source": [
        "## ▶ Creating a delta table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hk7GI3f5P6Il"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import Row\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "first_insert_ts = datetime.now()\n",
        "\n",
        "df = spark.createDataFrame([\n",
        "        Row(id=1, \n",
        "            name='Oliver',\n",
        "            salary=2000.00,\n",
        "            gender='M',\n",
        "            inserted_at=first_insert_ts,\n",
        "            updated_at=None\n",
        "        ),\n",
        "        Row(id=2, \n",
        "            name='Agata', \n",
        "            salary=2800.00,\n",
        "            gender='F',\n",
        "            inserted_at=first_insert_ts,\n",
        "            updated_at=None\n",
        "        ),\n",
        "        Row(id=3, \n",
        "            name='Lola', \n",
        "            salary=4500.00,\n",
        "            gender='F',\n",
        "            inserted_at=first_insert_ts,\n",
        "            updated_at=None\n",
        "        )\n",
        "], schema=table_schema)\n",
        "\n",
        "# Waiting a time for ts change\n",
        "time.sleep(0.5)\n",
        "\n",
        "df.write.format(\"delta\").save(person_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNJoXTV_bGhF"
      },
      "source": [
        "## ▶ Showing DF using **DeltaTable** class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1TcfVGDxaP_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0878b2b6-9738-45d3-d6fa-f322112eaad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+------+------+--------------------------+----------+\n",
            "|id |name  |salary|gender|inserted_at               |updated_at|\n",
            "+---+------+------+------+--------------------------+----------+\n",
            "|1  |Oliver|2000.0|M     |2022-01-17 05:08:36.847056|null      |\n",
            "|2  |Agata |2800.0|F     |2022-01-17 05:08:36.847056|null      |\n",
            "|3  |Lola  |4500.0|F     |2022-01-17 05:08:36.847056|null      |\n",
            "+---+------+------+------+--------------------------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "deltaTable = DeltaTable.forPath(spark, person_path)\n",
        "\n",
        "deltaTable.toDF().orderBy('id').show(200, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0ZvuaVMbs44"
      },
      "source": [
        "## ▶ Performing a merge operation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9OTuVPFgcBmq"
      },
      "outputs": [],
      "source": [
        "second_merge_ts = datetime.now()\n",
        "\n",
        "# I'll use this dataframe to perform a merge operation\n",
        "df_merge = spark.createDataFrame([\n",
        "         Row(id=4, \n",
        "            name='Paula',\n",
        "            salary=5400.00,\n",
        "            gender='F',\n",
        "            inserted_at=second_merge_ts, \n",
        "            updated_at=None                 \n",
        "        ),\n",
        "        Row(id=1, \n",
        "            name='Oliver',\n",
        "            salary=3000.00,\n",
        "            gender='M',\n",
        "            inserted_at = None, \n",
        "            updated_at = second_merge_ts   \n",
        "        )\n",
        "])\n",
        "\n",
        "\n",
        "when_match_upd_val = {\n",
        "    \"id\": col(\"source.id\"),\n",
        "    \"name\": col(\"source.name\"),\n",
        "    \"salary\": col(\"source.salary\"),\n",
        "    \"gender\": col(\"source.gender\"),\n",
        "    \"updated_at\": col(\"source.updated_at\"),\n",
        "    \"inserted_at\": col(\"target.inserted_at\")\n",
        "}\n",
        "\n",
        "deltaTable.alias(\"target\") \\\n",
        "    .merge(df_merge.alias(\"source\"), \"target.id = source.id\") \\\n",
        "    .whenMatchedUpdate(set=when_match_upd_val) \\\n",
        "    .whenNotMatchedInsertAll() \\\n",
        "    .execute()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BvvH6seddfXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "086a295e-db7b-41b9-b252-0c58b59700a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+------+------+--------------------------+--------------------------+\n",
            "|id |name  |salary|gender|inserted_at               |updated_at                |\n",
            "+---+------+------+------+--------------------------+--------------------------+\n",
            "|1  |Oliver|3000.0|M     |2022-01-17 05:08:36.847056|2022-01-17 05:09:02.247944|\n",
            "|2  |Agata |2800.0|F     |2022-01-17 05:08:36.847056|null                      |\n",
            "|3  |Lola  |4500.0|F     |2022-01-17 05:08:36.847056|null                      |\n",
            "|4  |Paula |5400.0|F     |2022-01-17 05:09:02.247944|null                      |\n",
            "+---+------+------+------+--------------------------+--------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "deltaTable.toDF().orderBy('id').show(200, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-H3IUAgjU8t"
      },
      "source": [
        "## ▶ Performing a delete operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C8e5yhyIeqzS"
      },
      "outputs": [],
      "source": [
        "deltaTable.delete(condition=expr(\"id = 3\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mSl_BwPRjrU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e19ef71-ac36-4d9e-f75b-d41e725d7dca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+------+------+--------------------------+--------------------------+\n",
            "|id |name  |salary|gender|inserted_at               |updated_at                |\n",
            "+---+------+------+------+--------------------------+--------------------------+\n",
            "|1  |Oliver|3000.0|M     |2022-01-17 05:08:36.847056|2022-01-17 05:09:02.247944|\n",
            "|2  |Agata |2800.0|F     |2022-01-17 05:08:36.847056|null                      |\n",
            "|4  |Paula |5400.0|F     |2022-01-17 05:09:02.247944|null                      |\n",
            "+---+------+------+------+--------------------------+--------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "deltaTable.toDF().orderBy('id').show(200, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Travel\n",
        "\n",
        "Another interesting feature of Delta is the capacity to navigate in table versions using \"DESCRIBE HISTORY\" command, each operation can be noticed in dataframe below."
      ],
      "metadata": {
        "id": "WQijYLAmzpQF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0TVrfX8Xks1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6084f1f0-f946-4413-aa43-4532bd6a8ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------------+---------+\n",
            "|version|timestamp              |operation|\n",
            "+-------+-----------------------+---------+\n",
            "|0      |2022-01-17 05:08:45.066|WRITE    |\n",
            "|1      |2022-01-17 05:09:06.3  |MERGE    |\n",
            "|2      |2022-01-17 05:09:13.982|DELETE   |\n",
            "+-------+-----------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(f\"\"\"\n",
        "\n",
        "DESCRIBE HISTORY '{person_path}'  \n",
        "\n",
        "\"\"\").selectExpr(\"version\", \"timestamp\", \"operation\") \\\n",
        "    .orderBy(\"version\") \\\n",
        "    .show(200, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using a specific version\n",
        "\n",
        "Selecting the first version of table."
      ],
      "metadata": {
        "id": "bKyE7mNA2hKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_old_version = spark.read.format(\"delta\") \\\n",
        "                           .option(\"versionAsOf\", 0) \\\n",
        "                           .load(person_path)\n",
        "\n",
        "df_old_version.orderBy(\"id\").show(200, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJyiZ0C70sHa",
        "outputId": "b01cbcc8-8d4a-48c2-fbc3-f172a8f75fa2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+------+------+--------------------------+----------+\n",
            "|id |name  |salary|gender|inserted_at               |updated_at|\n",
            "+---+------+------+------+--------------------------+----------+\n",
            "|1  |Oliver|2000.0|M     |2022-01-17 05:08:36.847056|null      |\n",
            "|2  |Agata |2800.0|F     |2022-01-17 05:08:36.847056|null      |\n",
            "|3  |Lola  |4500.0|F     |2022-01-17 05:08:36.847056|null      |\n",
            "+---+------+------+------+--------------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zeiMBolQ47aN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "basic_delta_lake_usage.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM01k5BYo2tZ74xeQ8XgY7m",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}