{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BasicHudiUpsert.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPk81Z7fYwL0Fg7ZcUE+nwP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DenysNunes/data-examples/blob/main/spark/intermediate/BasicHudiUpsert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hudi table upsert basic example\n",
        "\n",
        "Example using Apache Hudi to create a table with UPSERT feature. <br>\n",
        "This technique can be find [here](https://hudi.apache.org/docs/quick-start-guide)."
      ],
      "metadata": {
        "id": "A9tizpsRYO3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init spark\n",
        "\n",
        "Creating a session with default configurations and all dependencies."
      ],
      "metadata": {
        "id": "oOADaHCa5pMt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf0ryjg55BLU",
        "outputId": "44326c91-f368-43c6-a82a-2743eab9452a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tree is already the newest version (1.7.0-5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install -q pyspark==3.1.1\n",
        "!sudo apt install tree\n",
        "!rm -rf /tmp/hudi/persons/\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName(\"New Session Example\") \\\n",
        "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-avro_2.12:3.0.1,org.apache.hudi:hudi-spark-bundle_2.12:0.7.0\") \\\n",
        "    .config(\"spark.sql.hive.convertMetastoreParquet\", \"false\") \\\n",
        "    .enableHiveSupport() \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sql(\"DROP TABLE IF EXISTS tb_person\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating two dataframes with diferent times"
      ],
      "metadata": {
        "id": "irucRGpJYxqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import Row\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "df1 = spark.createDataFrame([\n",
        "        Row(id=1, name='John', ts=time.mktime(datetime.now().timetuple())),\n",
        "        Row(id=2, name='Maria', ts=time.mktime(datetime.now().timetuple())),\n",
        "        Row(id=3, name='Ben', ts=time.mktime(datetime.now().timetuple()))\n",
        "])\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        "df2 = spark.createDataFrame([\n",
        "        Row(id=1, name='Ana', ts=time.mktime(datetime.now().timetuple())),\n",
        "])"
      ],
      "metadata": {
        "id": "5o3Sqquw-1wE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hudi_options = {\n",
        "    'hoodie.table.name': \"tb_person\",\n",
        "    'hoodie.datasource.write.recordkey.field': 'id',\n",
        "    'hoodie.datasource.write.table.name': \"tb_person\",\n",
        "    'hoodie.datasource.write.operation': 'upsert',\n",
        "    'hoodie.datasource.write.precombine.field': 'ts',\n",
        "    'hoodie.combine.before.upsert': True,\n",
        "    'hoodie.upsert.shuffle.parallelism': 2,\n",
        "    'hoodie.insert.shuffle.parallelism': 2\n",
        "}\n",
        "\n",
        "df1.write.format(\"hudi\") \\\n",
        "    .options(**hudi_options) \\\n",
        "    .mode(\"append\") \\\n",
        "    .save(\"/tmp/hudi/persons/\")"
      ],
      "metadata": {
        "id": "qyBm8pHGEr7y"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ID 1 = John"
      ],
      "metadata": {
        "id": "MIuIeM9RZMWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.load(format='hudi', path='/tmp/hudi/persons/default/').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmVlnY7_FQff",
        "outputId": "d2a09b2e-bd33-4128-b569-8a88077436e3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+------------------+----------------------+--------------------+---+-----+-------------+\n",
            "|_hoodie_commit_time|_hoodie_commit_seqno|_hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name| id| name|           ts|\n",
            "+-------------------+--------------------+------------------+----------------------+--------------------+---+-----+-------------+\n",
            "|     20220106215535|  20220106215535_0_5|                 2|               default|73fdfb94-015a-4b1...|  2|Maria|1.641503146E9|\n",
            "|     20220106215535|  20220106215535_0_6|                 1|               default|73fdfb94-015a-4b1...|  1| John|1.641503146E9|\n",
            "|     20220106215535|  20220106215535_0_7|                 3|               default|73fdfb94-015a-4b1...|  3|  Ben|1.641503146E9|\n",
            "+-------------------+--------------------+------------------+----------------------+--------------------+---+-----+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.write.format(\"hudi\") \\\n",
        "    .options(**hudi_options) \\\n",
        "    .mode(\"append\") \\\n",
        "    .save(\"/tmp/hudi/persons/\")"
      ],
      "metadata": {
        "id": "kfvmSg-0FWrA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ID 1 = Ana"
      ],
      "metadata": {
        "id": "OTvtBR8KZUD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.load(format='hudi', path='/tmp/hudi/persons/default/').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmhxM_FQFaTg",
        "outputId": "4f07eacf-8158-4033-b359-adde3cf64789"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+------------------+----------------------+--------------------+---+-----+-------------+\n",
            "|_hoodie_commit_time|_hoodie_commit_seqno|_hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name| id| name|           ts|\n",
            "+-------------------+--------------------+------------------+----------------------+--------------------+---+-----+-------------+\n",
            "|     20220106210556|  20220106210556_0_1|                 2|               default|73fdfb94-015a-4b1...|  2|Maria|1.641503146E9|\n",
            "|     20220106210607|  20220106210607_0_4|                 1|               default|73fdfb94-015a-4b1...|  1|  Ana|1.641503151E9|\n",
            "|     20220106210556|  20220106210556_0_3|                 3|               default|73fdfb94-015a-4b1...|  3|  Ben|1.641503146E9|\n",
            "+-------------------+--------------------+------------------+----------------------+--------------------+---+-----+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tree /tmp/hudi/persons/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL5xKqygHkcH",
        "outputId": "08eb4a8f-3e41-4daa-ecd3-c2c0cc85fa30"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/hudi/persons/\n",
            "└── default\n",
            "    ├── dde821ac-fdb2-4c60-ac1c-a1321d16a407-0_0-21-22_20220106205459.parquet\n",
            "    └── dde821ac-fdb2-4c60-ac1c-a1321d16a407-0_0-54-54_20220106205510.parquet\n",
            "\n",
            "1 directory, 2 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating table in metastore"
      ],
      "metadata": {
        "id": "rTytgRgQZhcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "\n",
        "CREATE EXTERNAL TABLE `tb_person`(\n",
        "  `_hoodie_commit_time` string,\n",
        "  `_hoodie_commit_seqno` string,\n",
        "  `_hoodie_record_key` string,\n",
        "  `_hoodie_partition_path` string,\n",
        "  `_hoodie_file_name` string,\n",
        "  `id` long,\n",
        "  `name` string,\n",
        "  `ts` double)\n",
        "ROW FORMAT SERDE\n",
        "  'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
        "STORED AS INPUTFORMAT\n",
        "  'org.apache.hudi.hadoop.HoodieParquetInputFormat'\n",
        "OUTPUTFORMAT\n",
        "  'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'\n",
        "LOCATION\n",
        "  '/tmp/hudi/persons/default'\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxLVcOJDKA2H",
        "outputId": "ef30be78-5777-48df-a9d7-17d4b4aaa4ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "\n",
        "select id,\n",
        "       name, \n",
        "       from_unixtime(ts,'MM-dd-yyyy HH:mm:ss') as ts \n",
        "from  tb_person\n",
        "order by id\n",
        "\n",
        "\"\"\").show(20, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqCQcq9TMDod",
        "outputId": "8a99e09b-0d19-4e62-fc21-4dbc2241fa90"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+-------------------+\n",
            "|id |name |ts                 |\n",
            "+---+-----+-------------------+\n",
            "|1  |Ana  |01-06-2022 21:05:51|\n",
            "|2  |Maria|01-06-2022 21:05:46|\n",
            "|3  |Ben  |01-06-2022 21:05:46|\n",
            "+---+-----+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9Pb7-t8HMSiG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
