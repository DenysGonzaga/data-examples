{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataframes",
      "provenance": [],
      "authorship_tag": "ABX9TyNpcTVnjIk1UajCLLZ/xpOg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DenysNunes/data-examples/blob/main/spark/basic/dataframes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zug0kpwH_Lcl"
      },
      "source": [
        "# **Init spark**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNmUfQhH-1NS"
      },
      "source": [
        "!pip install -q pyspark==3.1.1\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName(\"New Session Example\") \\\n",
        "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "    .enableHiveSupport() \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ1lSp09_Q7Y"
      },
      "source": [
        "## **Single dataframe using Row object**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5NVzUhY-wEY",
        "outputId": "ffcadfd0-d609-4dfc-b8f4-c4c2d63f338d"
      },
      "source": [
        "from pyspark.sql.types import Row\n",
        "\n",
        "raw_rows = [\n",
        "        Row(id=1, name='Jonh'),\n",
        "        Row(id=2, name='Maria'),\n",
        "        Row(id=3, name='Ben')\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(raw_rows)\n",
        "\n",
        "df.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id| name|\n",
            "+---+-----+\n",
            "|  1| Jonh|\n",
            "|  2|Maria|\n",
            "|  3|  Ben|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HKWwcvNGaip"
      },
      "source": [
        "## **Using complex data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0ANodVQAgIz",
        "outputId": "cd61a6e5-7782-4166-988d-66cb1dbc4972"
      },
      "source": [
        "raw_rows_2 = [\n",
        "        Row(id=1, name='Jonh', animals=['cat', 'dog']),\n",
        "        Row(id=2, name='Maria', animals=['monkey']),\n",
        "        Row(id=3, name='Ben', animals=['cat', 'rat'])\n",
        "]\n",
        "\n",
        "df_2 = spark.createDataFrame(raw_rows_2)\n",
        "df_2.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+\n",
            "| id| name|   animals|\n",
            "+---+-----+----------+\n",
            "|  1| Jonh|[cat, dog]|\n",
            "|  2|Maria|  [monkey]|\n",
            "|  3|  Ben|[cat, rat]|\n",
            "+---+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT1Ht_nZHUrq"
      },
      "source": [
        "## **Dataframe with json schema**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyRayfFbGoso",
        "outputId": "bc097e65-3f01-44a3-842e-ba058be078a3"
      },
      "source": [
        "from pyspark.sql.types import StructType\n",
        "\n",
        "raw_rows_3 = [\n",
        "        [1, 'Jonh', ['cat', 'dog']],\n",
        "        [2, 'Maria', ['monkey']],\n",
        "        [3, 'Ben', ['cat', 'rat']]\n",
        "]\n",
        "\n",
        "schema = {\n",
        "   \"fields\":[\n",
        "      {\n",
        "         \"metadata\":{\n",
        "            \n",
        "         },\n",
        "         \"name\":\"id\",\n",
        "         \"nullable\":True,\n",
        "         \"type\":\"long\"\n",
        "      },\n",
        "      {\n",
        "         \"metadata\":{\n",
        "            \n",
        "         },\n",
        "         \"name\":\"name\",\n",
        "         \"nullable\":True,\n",
        "         \"type\":\"string\"\n",
        "      },\n",
        "      {\n",
        "         \"metadata\":{\n",
        "            \n",
        "         },\n",
        "         \"name\":\"animals\",\n",
        "         \"nullable\":True,\n",
        "         \"type\":{\n",
        "            \"containsNull\":True,\n",
        "            \"elementType\":\"string\",\n",
        "            \"type\":\"array\"\n",
        "         }\n",
        "      }\n",
        "   ],\n",
        "   \"type\":\"struct\"\n",
        "}\n",
        "\n",
        "struct_schema = StructType.fromJson(schema)\n",
        "\n",
        "df_3 = spark.createDataFrame(raw_rows_3, struct_schema)\n",
        "df_3.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+\n",
            "| id| name|   animals|\n",
            "+---+-----+----------+\n",
            "|  1| Jonh|[cat, dog]|\n",
            "|  2|Maria|  [monkey]|\n",
            "|  3|  Ben|[cat, rat]|\n",
            "+---+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndKtXcfKHaO8"
      },
      "source": [
        "## **Dataframe with typed schema**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4ZfU3IkJEgV",
        "outputId": "b563c0f3-e276-4647-b0ca-e409c8c11026"
      },
      "source": [
        "from pyspark.sql.types import  StructField, StructType, StringType, LongType, ArrayType\n",
        "\n",
        "raw_rows_4 = [\n",
        "        [1, 'Jonh', ['cat', 'dog']],\n",
        "        [2, 'Maria', ['monkey']],\n",
        "        [3, 'Ben', ['cat', 'rat']]\n",
        "]\n",
        "\n",
        "struct_schema_2 = StructType(\n",
        "    [StructField('id',LongType(),True),\n",
        "     StructField('name', StringType(),True), \n",
        "     StructField('animals', ArrayType(StringType(),True),True)])\n",
        "\n",
        "df_4 = spark.createDataFrame(raw_rows_4, struct_schema_2)\n",
        "df_4.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+\n",
            "| id| name|   animals|\n",
            "+---+-----+----------+\n",
            "|  1| Jonh|[cat, dog]|\n",
            "|  2|Maria|  [monkey]|\n",
            "|  3|  Ben|[cat, rat]|\n",
            "+---+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyvPPcaRKFYD"
      },
      "source": [
        "## **Running SQL over dataframes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms6a8MITKFCh",
        "outputId": "4b5579aa-026b-46aa-a67f-6ea243cf2ba4"
      },
      "source": [
        "raw_rows_5 = [\n",
        "        Row(id=1, name='Jonh', animals=['cat', 'dog']),\n",
        "        Row(id=2, name='Maria', animals=['monkey']),\n",
        "        Row(id=3, name='Ben', animals=['cat', 'rat'])\n",
        "]\n",
        "\n",
        "df_5 = spark.createDataFrame(raw_rows_5)\n",
        "df_5.registerTempTable(\"tb_teste_table\")\n",
        "\n",
        "df_6 = spark.sql(\"\"\"\n",
        "    SELECT * FROM tb_teste_table WHERE array_contains(animals, 'cat')\n",
        "\"\"\")\n",
        "\n",
        "df_6.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+----------+\n",
            "| id|name|   animals|\n",
            "+---+----+----------+\n",
            "|  1|Jonh|[cat, dog]|\n",
            "|  3| Ben|[cat, rat]|\n",
            "+---+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMic5b37JFcj"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}